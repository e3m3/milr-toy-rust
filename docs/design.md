---

#   Copyright

Copyright 2024, Giordano Salvador
SPDX-License-Identifier: BSD-3-Clause and CC-BY-SA-4.0

Author/Maintainer:  Giordano Salvador <73959795+e3m3@users.noreply.github.com>


#   Rust source (`src/`)

The Rust source implements a frontend for generation of the MLIR assembly.

The frontend is also responsible for driving the optimization pipeline and calling the appropriate
backend lowering passes.


#   MLIR source (`mlir/`)

The AST/MLIR assembly is to be parsed by the autogenerated MLIR tablegen modules in preparation
for further processing.

The MLIR source contains the definitions for the optimization driver (`opt-mlp`), as well as the
registration of the MLIR dialect (`dialect-mlp.{h,td}`) and its operations (`ops-mlp.{h,td}`).

The implementation boilerplate here is currently modeled after the MLIR repository toy example [[1]],
and the MLIR standalone dialect template [[2]] until a more complex example can be constructed.


#   Algebraic semantics

**Warning: Matrix multiplication for tensors is experimental and likely buggy**

The frontend semantics have been extended from the original MLIR toy specification to allow
matrix multiplication using the dot-star operator (`.*`).

For example, the multiplication of the `a` and `b` tensors would result in a shape inference
error in the original specification:

```mlp
def test() {
    var a<2,1,3> = [[1, 2], [3, 4], [5, 6]];
    var b<2,3> = [[1, 2, 3], [4, 5, 6]];
    return a * b;                           // Shape inference error <3,2> != <2,3>
}
```

In this implementation the definition of test would be a valid program:

```mlp
def test() {
    var a<3,2> = [[1, 2], [3, 4], [5, 6]];
    var b<2,3> = [[1, 2, 3], [4, 5, 6]];
    return a .* b;                          // Result returned is of shape <3,3>
}
```

There are also ramifications on the language design in the compiler backend, which must support
allocation and return of differently shaped tensors, both outer and inner product based on
the number of dimensions contracted from the two-input tensors of the infix `.*` operator.

See tests `tests/lit-tests/sem_product_1.mlp` and `tests/lit-tests/sem_ch1_4.mlp` for walkthrough
examples of the semantic processing for specializations of tensor products.


#   Workflow

*   `build.rs`:

    The build script drives the compilation of the tablegen and C++ components of the MLIR dialect.
    This script roughly follows the structure of the CMake components required for building a MLIR
    dialect standalone, but does so by calling the downstream tools directly without introducing
    CMake as a dependency.

    The current challenge is to interop the Rust frontend AST with the tablegen infrastructure for 
    driving optimizations on the language operations.
    
    *   The naive solution is to reimplement the AST and parser within C++ for interop, leveraging
        tablegen defined builder operations as specified in the MLIR tutorial/examples.
        The downside of this is that the AST and parsing infrastructure will be duplicated in both
        Rust and C++ separately, which will be a source of bugs and wasted developer time.
        Requiring a C++ parser obviates the Rust frontend.
        However, the Rust frontend provides a smoother developer experience through higher level
        abstractions and improved compiler interactions with the developer.
        I would prefer to work with a Rust frontend.

    *   Is there a generic adaptor for the AST which can be included from the tablegen definition?
        The `dialect-mlp.h.inc` header automatically generates an explicit prototype for the
        construction of the dialect instance given a MLIR context.
        The definition of this constructor is currently missing during build.

        ```
        clang++ stderr:
        Undefined symbols for architecture arm64:
          "mlir::mlp::MlpDialect::MlpDialect(mlir::MLIRContext*)", referenced from:
              mlir::mlp::MlpDialect* mlir::MLIRContext::getOrLoadDialect<mlir::mlp::MlpDialect>()::'lambda'()::operator()() const in opt-mlp-676c67.o
          "mlir::detail::TypeIDResolver<mlir::mlp::MlpDialect, void>::id", referenced from:
              mlir::detail::TypeIDResolver<mlir::mlp::MlpDialect, void>::resolveTypeID() in opt-mlp-676c67.o
        ```

    *   From the MLIR FAQ, there is a claim that a frontend does not need to register a dialect
        directly [[1]]:

            Finally, dialects can be registered with the context.
            The sole purpose of the registration is to make these dialects available for the textual
            parser used by tools like mlir-opt or mlir-translate.
            A compiler frontend emitting the IR programmatically and invoking a pass pipeline would
            never need to register any dialects.

        However, my understanding is that the pass pipeline is driven by the `opt` tool which is
        stated to depend on the textual parser which expects dialect registration with the context.

    *   Does using the MLIR C API mitigate this issue (i.e., using the mlir-sys package directly)?
        Or will this require extra effort avoided by using the tablegen autogeneration?

        *   The best solution is probably to use a combination of vanilla dialects in the frontend.
            Will generate directly via C API.
            Disable 'build.rs' (probably will delete).


#   References

[1]:    https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/

[2]:    https://github.com/jmgorius/mlir-standalone-template

[3]:    https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management

[4]:    https://www.mathworks.com/help/matlab/ref/tensorprod.html

1.  `https://mlir.llvm.org/docs/Tutorials/Toy/Ch-2/`

1.  `https://github.com/jmgorius/mlir-standalone-template`

1.  `https://mlir.llvm.org/getting_started/Faq/#registered-loaded-dependent-whats-up-with-dialects-management`

1.  `https://www.mathworks.com/help/matlab/ref/tensorprod.html`
